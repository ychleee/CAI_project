# Pythia 1.4B Configuration for Development/Testing
# Optimized for T4 GPU (free Colab tier)

model:
  name: "EleutherAI/pythia-1.4b"
  model_type: "causal_lm"
  trust_remote_code: true
  
  # Quantization settings for memory efficiency
  quantization:
    enabled: true
    bits: 8  # 8-bit quantization for T4
    compute_dtype: "float16"
  
  # LoRA configuration
  lora:
    enabled: true
    r: 16  # Rank
    alpha: 32  # Scaling parameter
    dropout: 0.1
    target_modules: ["query_key_value", "dense", "dense_h_to_4h", "dense_4h_to_h"]
    
  # Model settings
  max_length: 512  # Reduced for memory
  gradient_checkpointing: true

# Training configuration
training:
  # Batch settings
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 8
  eval_accumulation_steps: 4
  
  # Optimization
  learning_rate: 2e-5
  lr_scheduler_type: "cosine"
  warmup_steps: 100
  weight_decay: 0.01
  
  # Training steps
  num_train_epochs: 3
  max_steps: -1  # Set to positive value to override epochs
  
  # Evaluation
  evaluation_strategy: "steps"
  eval_steps: 100
  save_strategy: "steps"
  save_steps: 200
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  
  # Efficiency
  fp16: true
  fp16_opt_level: "O2"
  gradient_clip_value: 1.0
  
  # Logging
  logging_steps: 10
  report_to: ["wandb", "tensorboard"]
  
# PPO specific settings for RL stage
ppo:
  # Rollout settings
  num_rollout_samples: 256
  rollout_batch_size: 16
  
  # PPO hyperparameters
  ppo_epochs: 4
  value_loss_coef: 0.5
  entropy_coef: 0.01
  cliprange: 0.2
  cliprange_value: 0.2
  gamma: 0.99
  lam: 0.95
  
  # Optimization
  learning_rate: 1e-5
  max_grad_norm: 0.5
  
# Memory optimization
memory:
  gradient_checkpointing: true
  mixed_precision: "fp16"
  optim: "adamw_8bit"  # 8-bit optimizer
  
# Data loading
data:
  max_seq_length: 512
  preprocessing_num_workers: 2
  dataloader_num_workers: 2
  remove_unused_columns: true
  
# Checkpoint settings  
checkpoint:
  resume_from_checkpoint: null
  push_to_hub: false
  hub_model_id: null