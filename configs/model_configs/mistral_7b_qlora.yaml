# Mistral 7B Configuration for Production
# Optimized for A100 GPU (Colab Pro) or careful T4 usage

model:
  name: "mistralai/Mistral-7B-Instruct-v0.2"
  model_type: "causal_lm"
  trust_remote_code: true
  
  # Quantization settings for QLoRA
  quantization:
    enabled: true
    bits: 4  # 4-bit quantization for 7B model
    compute_dtype: "bfloat16"  # Use bfloat16 if available
    bnb_4bit_quant_type: "nf4"  # Normal Float 4
    bnb_4bit_use_double_quant: true  # Double quantization
  
  # LoRA configuration
  lora:
    enabled: true
    r: 64  # Higher rank for better performance
    alpha: 128  # Alpha = 2 * r is common
    dropout: 0.1
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    modules_to_save: ["embed_tokens", "lm_head"]  # Also train embeddings
    
  # Model settings
  max_length: 1024  # Longer context for better reasoning
  gradient_checkpointing: true
  use_cache: false  # Disable during training

# Training configuration
training:
  # Batch settings (adjust based on GPU memory)
  per_device_train_batch_size: 1  # Start small
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 16  # Effective batch = 16
  eval_accumulation_steps: 8
  
  # Optimization
  learning_rate: 1e-4  # Higher LR for LoRA
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.03
  weight_decay: 0.0
  
  # Training steps
  num_train_epochs: 2  # Fewer epochs for large model
  max_steps: -1
  
  # Evaluation
  evaluation_strategy: "steps"
  eval_steps: 50
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  
  # Efficiency
  bf16: true  # Use bf16 if available (A100)
  fp16: false  # Fallback to fp16 if bf16 not available
  fp16_opt_level: "O2"
  gradient_clip_value: 1.0
  
  # Logging
  logging_steps: 5
  report_to: ["wandb", "tensorboard"]
  
# PPO specific settings for RL stage
ppo:
  # Rollout settings
  num_rollout_samples: 512
  rollout_batch_size: 32
  
  # PPO hyperparameters
  ppo_epochs: 4
  value_loss_coef: 0.5
  entropy_coef: 0.01
  cliprange: 0.2
  cliprange_value: 0.2
  gamma: 0.99
  lam: 0.95
  
  # Optimization
  learning_rate: 5e-6  # Lower LR for fine-tuning
  max_grad_norm: 0.5
  
# Memory optimization
memory:
  gradient_checkpointing: true
  mixed_precision: "bf16"  # or "fp16"
  optim: "paged_adamw_8bit"  # Paged optimizer for large models
  
# Data loading
data:
  max_seq_length: 1024
  preprocessing_num_workers: 4
  dataloader_num_workers: 4
  remove_unused_columns: true
  pad_to_multiple_of: 8  # Efficient padding
  
# Checkpoint settings  
checkpoint:
  resume_from_checkpoint: null
  push_to_hub: false
  hub_model_id: null
  save_safetensors: true  # Use safetensors format